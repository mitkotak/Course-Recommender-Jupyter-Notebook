{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from src.utilities.gridSearch import GridSearchEstimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection       import train_test_split, GridSearchCV\n",
    "from sklearn.utils                 import resample\n",
    "\n",
    "from sklearn.ensemble              import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.svm                   import SVC\n",
    "from sklearn.neighbors             import KNeighborsClassifier\n",
    "from sklearn.linear_model          import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes           import GaussianNB\n",
    "from sklearn.ensemble              import AdaBoostClassifier, GradientBoostingClassifier\n",
    "\n",
    "from sklearn.metrics               import classification_report, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics               import make_scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Presentation Notebook 1\n",
    "\n",
    "This notebook is here to summarize our findings for both the feature-engineered ML model and the sparse grades matrix ML model.\n",
    "\n",
    "The students part of this effort are: Skyler Shi, Danny Ferriss, Mit Kotak, Jarett Brunner, Divya Bhati. \\\n",
    "The instructor of our efforts is: Hannah Christenson."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature-Engineered ML Model\n",
    "\n",
    "Our initial idea was to engineer several features by intuition and use those features to predict the grades of GIES students. \\\n",
    "These are the features we finally decided to assemble:\n",
    "- Previous Semester GPA\n",
    "- Cumulative GPA to date\n",
    "- Number of Credits to date\n",
    "- Concentration Cumulative GPA\n",
    "- Concentration Number of Credits\n",
    "- Business Core Cumulative GPA\n",
    "- Business Core Number of Credits\n",
    "- Prerequisites GPA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EDW_PERS_ID</th>\n",
       "      <th>term_count</th>\n",
       "      <th>Majors_List</th>\n",
       "      <th>Course_name</th>\n",
       "      <th>course_grade</th>\n",
       "      <th>prev_sem_GPA</th>\n",
       "      <th>cum_GPA</th>\n",
       "      <th>num_credits</th>\n",
       "      <th>cum_GPA_concentration</th>\n",
       "      <th>num_credits_concentration</th>\n",
       "      <th>cum_GPA_business_core</th>\n",
       "      <th>num_credits_business_core</th>\n",
       "      <th>prereq_GPA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>25539</td>\n",
       "      <td>1</td>\n",
       "      <td>Accountancy</td>\n",
       "      <td>BADM 449</td>\n",
       "      <td>B+</td>\n",
       "      <td>3.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>25539</td>\n",
       "      <td>2</td>\n",
       "      <td>Accountancy</td>\n",
       "      <td>ACCY 301</td>\n",
       "      <td>A</td>\n",
       "      <td>3.33</td>\n",
       "      <td>3.33</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.33</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>25539</td>\n",
       "      <td>3</td>\n",
       "      <td>Accountancy</td>\n",
       "      <td>ACCY 303</td>\n",
       "      <td>A</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.67</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.33</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>25539</td>\n",
       "      <td>4</td>\n",
       "      <td>Accountancy</td>\n",
       "      <td>ACCY 302</td>\n",
       "      <td>A</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.78</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.33</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>25539</td>\n",
       "      <td>5</td>\n",
       "      <td>Accountancy</td>\n",
       "      <td>ACCY 304</td>\n",
       "      <td>B+</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.83</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.33</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   EDW_PERS_ID  term_count  Majors_List Course_name course_grade  \\\n",
       "0        25539           1  Accountancy    BADM 449           B+   \n",
       "1        25539           2  Accountancy    ACCY 301            A   \n",
       "2        25539           3  Accountancy    ACCY 303            A   \n",
       "3        25539           4  Accountancy    ACCY 302            A   \n",
       "4        25539           5  Accountancy    ACCY 304           B+   \n",
       "\n",
       "   prev_sem_GPA  cum_GPA  num_credits  cum_GPA_concentration  \\\n",
       "0          3.50     0.00          0.0                    0.0   \n",
       "1          3.33     3.33          3.0                    0.0   \n",
       "2          4.00     3.67          6.0                    4.0   \n",
       "3          4.00     3.78          9.0                    4.0   \n",
       "4          4.00     3.83         12.0                    4.0   \n",
       "\n",
       "   num_credits_concentration  cum_GPA_business_core  \\\n",
       "0                        0.0                   0.00   \n",
       "1                        0.0                   3.33   \n",
       "2                        3.0                   3.33   \n",
       "3                        6.0                   3.33   \n",
       "4                        9.0                   3.33   \n",
       "\n",
       "   num_credits_business_core  prereq_GPA  \n",
       "0                        0.0         0.0  \n",
       "1                        3.0         0.0  \n",
       "2                        3.0         0.0  \n",
       "3                        3.0         0.0  \n",
       "4                        3.0         0.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_df = pd.read_csv('src/data/ml_ready.csv').drop(columns = ['Unnamed: 0'])\n",
    "ml_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Before we did any modeling, we cleaned up the distribution of grades\n",
    "\n",
    "We combined honors grades with non-honors grades. For example **\"AH\"** is combined with **\"A\"**. We thought this is justifiable because for most classes, most of the coursework of honors students and non-honors students is still the same.\n",
    "\n",
    "We also dropped grades with rare occurences such as **['W', 'PS', 'ABS', 'AU', 'NR']** because there were too few samples for them to be effectively predicted and they described occurences where the student doesn't finish the class. Whether a student finishes a class is not under our scope of investigation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_honors_grades(grade):\n",
    "    if grade[-1] == 'H':\n",
    "        return grade[0:-1]\n",
    "    else:\n",
    "        return grade\n",
    "\n",
    "ml_df.course_grade = ml_df.course_grade.apply(combine_honors_grades)\n",
    "ml_df = ml_df[~ml_df.course_grade.isin(['W', 'PS', 'ABS', 'AU', 'NR'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['prev_sem_GPA'              ,\n",
    "            'cum_GPA'                    ,\n",
    "            'num_credits'                ,\n",
    "            'cum_GPA_concentration'      ,\n",
    "            'num_credits_concentration'  ,\n",
    "            'cum_GPA_business_core'      ,\n",
    "            'num_credits_business_core'  ,\n",
    "            'prereq_GPA'                 ]\n",
    "\n",
    "X = ml_df[features]\n",
    "y = ml_df['course_grade']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. First, we tried predicting the letter grades.\n",
    "\n",
    "There were simply too many classes and not enough samples with bad grades for the machine learning model to be accurate.\n",
    "\n",
    "Below is an example of predictions being run on BADM 300."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.33      0.56      0.42       185\n",
      "          A+       0.35      0.29      0.32       117\n",
      "          A-       0.12      0.10      0.11       103\n",
      "           B       0.18      0.20      0.19       110\n",
      "          B+       0.14      0.13      0.14        67\n",
      "          B-       0.00      0.00      0.00        52\n",
      "           C       0.09      0.06      0.07        33\n",
      "          C+       0.07      0.03      0.04        35\n",
      "          C-       0.00      0.00      0.00        17\n",
      "           D       0.00      0.00      0.00         8\n",
      "          D+       0.00      0.00      0.00         4\n",
      "          D-       0.00      0.00      0.00         1\n",
      "           F       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.25       736\n",
      "   macro avg       0.10      0.11      0.10       736\n",
      "weighted avg       0.20      0.25      0.22       736\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get only samples that are BADM 300\n",
    "badm300 = ml_df[ml_df.Course_name == \"BADM 300\"]\n",
    "\n",
    "# train test split\n",
    "X = badm300[features]\n",
    "y = badm300['course_grade']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "# fit random forest classifier model\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X_train, y_train)\n",
    "predictions = rfc.predict(X_test)\n",
    "print(classification_report(y_test, predictions, zero_division = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Seeing the results, we decided to predict the Grades Bucketed.\n",
    "\n",
    "We decided to bucket together grades to promote separability within our models.\n",
    "- **['A+', 'A', 'A-', 'B+', 'B', 'B-']** are deemed **\"good\"** grades\n",
    "- **['C+', 'C', 'C-', 'D+', 'D', 'D-', 'F']** are deemed **\"bad\"** grades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bucket_grades(x):\n",
    "    if x in ['A+', 'A', 'A-', 'B+', 'B', 'B-']:\n",
    "        return \"good\"\n",
    "    if x in ['C+', 'C', 'C-', 'D+', 'D', 'D-', 'F']:\n",
    "        return \"bad\"\n",
    "\n",
    "grades_bucketed_df = ml_df.copy(deep = True)\n",
    "grades_bucketed_df['course_grade'] = grades_bucketed_df['course_grade'].apply(bucket_grades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "good    121342\n",
       "bad      12053\n",
       "Name: course_grade, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grades_bucketed_df.course_grade.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get only samples that are BADM 300\n",
    "badm300 = grades_bucketed_df[grades_bucketed_df.Course_name == \"BADM 300\"]\n",
    "\n",
    "# train test split\n",
    "X = badm300[features]\n",
    "y = badm300['course_grade']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our grades bucketed, we only have to predict two classes - \"good grade\" and \"bad grade\". The machine learning model should not choke as much. \\\n",
    "We run a gridsearch on some popular classifiers and track their performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for RandomForest\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done   5 out of   5 | elapsed:    6.9s finished\n",
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for KNN\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Running GridSearchCV for SVM\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for NaiveBayes\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Running GridSearchCV for AdaBoost\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done   5 out of   5 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for GradBoost\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done   5 out of   5 | elapsed:    0.9s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_37088060_08a4_11eb_a1c5_98460a89da96row0_col4 {\n",
       "            background-color:  lightgreen;\n",
       "        }    #T_37088060_08a4_11eb_a1c5_98460a89da96row2_col2 {\n",
       "            background-color:  lightgreen;\n",
       "        }    #T_37088060_08a4_11eb_a1c5_98460a89da96row2_col5 {\n",
       "            background-color:  lightgreen;\n",
       "        }    #T_37088060_08a4_11eb_a1c5_98460a89da96row3_col7 {\n",
       "            background-color:  lightgreen;\n",
       "        }    #T_37088060_08a4_11eb_a1c5_98460a89da96row4_col6 {\n",
       "            background-color:  lightgreen;\n",
       "        }    #T_37088060_08a4_11eb_a1c5_98460a89da96row5_col3 {\n",
       "            background-color:  lightgreen;\n",
       "        }    #T_37088060_08a4_11eb_a1c5_98460a89da96row5_col4 {\n",
       "            background-color:  lightgreen;\n",
       "        }</style><table id=\"T_37088060_08a4_11eb_a1c5_98460a89da96\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Estimator</th>        <th class=\"col_heading level0 col1\" >Parameters</th>        <th class=\"col_heading level0 col2\" >mean_precision % (high)</th>        <th class=\"col_heading level0 col3\" >mean_precision % (low)</th>        <th class=\"col_heading level0 col4\" >mean_recall % (high)</th>        <th class=\"col_heading level0 col5\" >mean_recall % (low)</th>        <th class=\"col_heading level0 col6\" >mean_f1 % (high)</th>        <th class=\"col_heading level0 col7\" >mean_f1 % (low)</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_37088060_08a4_11eb_a1c5_98460a89da96level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_37088060_08a4_11eb_a1c5_98460a89da96row0_col0\" class=\"data row0 col0\" >RandomForest</td>\n",
       "                        <td id=\"T_37088060_08a4_11eb_a1c5_98460a89da96row0_col1\" class=\"data row0 col1\" >{}</td>\n",
       "                        <td id=\"T_37088060_08a4_11eb_a1c5_98460a89da96row0_col2\" class=\"data row0 col2\" >0.886</td>\n",
       "                        <td id=\"T_37088060_08a4_11eb_a1c5_98460a89da96row0_col3\" class=\"data row0 col3\" >0.5203</td>\n",
       "                        <td id=\"T_37088060_08a4_11eb_a1c5_98460a89da96row0_col4\" class=\"data row0 col4\" >0.9738</td>\n",
       "                        <td id=\"T_37088060_08a4_11eb_a1c5_98460a89da96row0_col5\" class=\"data row0 col5\" >0.1815</td>\n",
       "                        <td id=\"T_37088060_08a4_11eb_a1c5_98460a89da96row0_col6\" class=\"data row0 col6\" >0.9278</td>\n",
       "                        <td id=\"T_37088060_08a4_11eb_a1c5_98460a89da96row0_col7\" class=\"data row0 col7\" >0.2688</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_37088060_08a4_11eb_a1c5_98460a89da96level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_37088060_08a4_11eb_a1c5_98460a89da96row1_col0\" class=\"data row1 col0\" >KNN</td>\n",
       "                        <td id=\"T_37088060_08a4_11eb_a1c5_98460a89da96row1_col1\" class=\"data row1 col1\" >{}</td>\n",
       "                        <td id=\"T_37088060_08a4_11eb_a1c5_98460a89da96row1_col2\" class=\"data row1 col2\" >0.8681</td>\n",
       "                        <td id=\"T_37088060_08a4_11eb_a1c5_98460a89da96row1_col3\" class=\"data row1 col3\" >0.1475</td>\n",
       "                        <td id=\"T_37088060_08a4_11eb_a1c5_98460a89da96row1_col4\" class=\"data row1 col4\" >0.9714</td>\n",
       "                        <td id=\"T_37088060_08a4_11eb_a1c5_98460a89da96row1_col5\" class=\"data row1 col5\" >0.0359</td>\n",
       "                        <td id=\"T_37088060_08a4_11eb_a1c5_98460a89da96row1_col6\" class=\"data row1 col6\" >0.9168</td>\n",
       "                        <td id=\"T_37088060_08a4_11eb_a1c5_98460a89da96row1_col7\" class=\"data row1 col7\" >0.0575</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_37088060_08a4_11eb_a1c5_98460a89da96level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_37088060_08a4_11eb_a1c5_98460a89da96row2_col0\" class=\"data row2 col0\" >SVM</td>\n",
       "                        <td id=\"T_37088060_08a4_11eb_a1c5_98460a89da96row2_col1\" class=\"data row2 col1\" >{}</td>\n",
       "                        <td id=\"T_37088060_08a4_11eb_a1c5_98460a89da96row2_col2\" class=\"data row2 col2\" >0.9199</td>\n",
       "                        <td id=\"T_37088060_08a4_11eb_a1c5_98460a89da96row2_col3\" class=\"data row2 col3\" >0.2411</td>\n",
       "                        <td id=\"T_37088060_08a4_11eb_a1c5_98460a89da96row2_col4\" class=\"data row2 col4\" >0.7109</td>\n",
       "                        <td id=\"T_37088060_08a4_11eb_a1c5_98460a89da96row2_col5\" class=\"data row2 col5\" >0.5959</td>\n",
       "                        <td id=\"T_37088060_08a4_11eb_a1c5_98460a89da96row2_col6\" class=\"data row2 col6\" >0.8017</td>\n",
       "                        <td id=\"T_37088060_08a4_11eb_a1c5_98460a89da96row2_col7\" class=\"data row2 col7\" >0.3428</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_37088060_08a4_11eb_a1c5_98460a89da96level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_37088060_08a4_11eb_a1c5_98460a89da96row3_col0\" class=\"data row3 col0\" >NaiveBayes</td>\n",
       "                        <td id=\"T_37088060_08a4_11eb_a1c5_98460a89da96row3_col1\" class=\"data row3 col1\" >{}</td>\n",
       "                        <td id=\"T_37088060_08a4_11eb_a1c5_98460a89da96row3_col2\" class=\"data row3 col2\" >0.9003</td>\n",
       "                        <td id=\"T_37088060_08a4_11eb_a1c5_98460a89da96row3_col3\" class=\"data row3 col3\" >0.38</td>\n",
       "                        <td id=\"T_37088060_08a4_11eb_a1c5_98460a89da96row3_col4\" class=\"data row3 col4\" >0.9158</td>\n",
       "                        <td id=\"T_37088060_08a4_11eb_a1c5_98460a89da96row3_col5\" class=\"data row3 col5\" >0.3377</td>\n",
       "                        <td id=\"T_37088060_08a4_11eb_a1c5_98460a89da96row3_col6\" class=\"data row3 col6\" >0.908</td>\n",
       "                        <td id=\"T_37088060_08a4_11eb_a1c5_98460a89da96row3_col7\" class=\"data row3 col7\" >0.3574</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_37088060_08a4_11eb_a1c5_98460a89da96level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "                        <td id=\"T_37088060_08a4_11eb_a1c5_98460a89da96row4_col0\" class=\"data row4 col0\" >AdaBoost</td>\n",
       "                        <td id=\"T_37088060_08a4_11eb_a1c5_98460a89da96row4_col1\" class=\"data row4 col1\" >{}</td>\n",
       "                        <td id=\"T_37088060_08a4_11eb_a1c5_98460a89da96row4_col2\" class=\"data row4 col2\" >0.8872</td>\n",
       "                        <td id=\"T_37088060_08a4_11eb_a1c5_98460a89da96row4_col3\" class=\"data row4 col3\" >0.5183</td>\n",
       "                        <td id=\"T_37088060_08a4_11eb_a1c5_98460a89da96row4_col4\" class=\"data row4 col4\" >0.973</td>\n",
       "                        <td id=\"T_37088060_08a4_11eb_a1c5_98460a89da96row4_col5\" class=\"data row4 col5\" >0.192</td>\n",
       "                        <td id=\"T_37088060_08a4_11eb_a1c5_98460a89da96row4_col6\" class=\"data row4 col6\" >0.9281</td>\n",
       "                        <td id=\"T_37088060_08a4_11eb_a1c5_98460a89da96row4_col7\" class=\"data row4 col7\" >0.2765</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_37088060_08a4_11eb_a1c5_98460a89da96level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "                        <td id=\"T_37088060_08a4_11eb_a1c5_98460a89da96row5_col0\" class=\"data row5 col0\" >GradBoost</td>\n",
       "                        <td id=\"T_37088060_08a4_11eb_a1c5_98460a89da96row5_col1\" class=\"data row5 col1\" >{}</td>\n",
       "                        <td id=\"T_37088060_08a4_11eb_a1c5_98460a89da96row5_col2\" class=\"data row5 col2\" >0.8863</td>\n",
       "                        <td id=\"T_37088060_08a4_11eb_a1c5_98460a89da96row5_col3\" class=\"data row5 col3\" >0.5229</td>\n",
       "                        <td id=\"T_37088060_08a4_11eb_a1c5_98460a89da96row5_col4\" class=\"data row5 col4\" >0.9738</td>\n",
       "                        <td id=\"T_37088060_08a4_11eb_a1c5_98460a89da96row5_col5\" class=\"data row5 col5\" >0.1842</td>\n",
       "                        <td id=\"T_37088060_08a4_11eb_a1c5_98460a89da96row5_col6\" class=\"data row5 col6\" >0.928</td>\n",
       "                        <td id=\"T_37088060_08a4_11eb_a1c5_98460a89da96row5_col7\" class=\"data row5 col7\" >0.271</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7ff98d75d990>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = {\n",
    "    'RandomForest': RandomForestClassifier(),\n",
    "    'KNN'         : KNeighborsClassifier(weights = \"distance\"),\n",
    "    'SVM'         : SVC(class_weight = \"balanced\"),\n",
    "    'NaiveBayes'  : GaussianNB(),\n",
    "    'AdaBoost'    : AdaBoostClassifier(),\n",
    "    'GradBoost'   : GradientBoostingClassifier()\n",
    "    \n",
    "}\n",
    "\n",
    "params = {\n",
    "    'RandomForest': {\n",
    "    },\n",
    "    'KNN': {\n",
    "    },\n",
    "    'SVM': {   \n",
    "    },\n",
    "    'NaiveBayes': {\n",
    "    },\n",
    "    'AdaBoost': {\n",
    "    },\n",
    "    'GradBoost': {\n",
    "    }\n",
    "}\n",
    "\n",
    "scoring = {\n",
    "    'precision % (high)': make_scorer(precision_score, pos_label = 'good'),\n",
    "    'precision % (low)':  make_scorer(precision_score, pos_label = 'bad'),\n",
    "    'recall % (high)':    make_scorer(recall_score, pos_label = 'good'),\n",
    "    'recall % (low)':     make_scorer(recall_score, pos_label = 'bad'),\n",
    "    'f1 % (high)':        make_scorer(f1_score, pos_label = 'good'),\n",
    "    'f1 % (low)':         make_scorer(f1_score, pos_label = 'bad'),\n",
    "}\n",
    "gs = GridSearchEstimators(models = models, params = params, scoring = scoring)\n",
    "gs.fit(X_train, y_train)\n",
    "gs.report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even with grades bucketed into two classes, we observe that for all ML models tried, the metrics for the good grade class are all very high, but the metrics for the bad grade class are all very low. The focus of our ML model should be to accurately predict the bad grade class, as that represents the students at risk.\n",
    "\n",
    "Hence, we definitely need to improve precision, recall, f1 for the bad grade class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. We Correct Class Imbalance to Improve Bad Grade Class metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without any sample size correction, ML models are all biased towards predicting good grade class more accurately because that produces the highest overall accuracy. \\\n",
    "We increase the number of bad grade samples to be the same as good grade samples through up-sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "badm300 = grades_bucketed_df[grades_bucketed_df.Course_name == \"ECON 302\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bad     2725\n",
       "good    2725\n",
       "Name: course_grade, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate majority and minority classes\n",
    "grades_good = badm300[badm300.course_grade == \"good\"]\n",
    "grades_bad  = badm300[badm300.course_grade == \"bad\"]\n",
    " \n",
    "# Upsample minority class\n",
    "badm300_bad_upsampled = resample(grades_bad, \n",
    "                                 replace = True,     # sample with replacement\n",
    "                                 n_samples = badm300.course_grade.value_counts()['good'],    # to match majority class\n",
    "                                 random_state = 123) # reproducible results\n",
    " \n",
    "# Combine majority class with upsampled minority class\n",
    "badm300_upsampled = pd.concat([grades_good, badm300_bad_upsampled])\n",
    " \n",
    "# Display new class counts\n",
    "badm300_upsampled.course_grade.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "X = badm300_upsampled[features]\n",
    "y = badm300_upsampled['course_grade']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for RandomForest\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done   5 out of   5 | elapsed:    1.4s finished\n",
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for KNN\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done   5 out of   5 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for SVM\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done   5 out of   5 | elapsed:    1.3s finished\n",
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for NaiveBayes\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Running GridSearchCV for AdaBoost\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done   5 out of   5 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for GradBoost\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done   5 out of   5 | elapsed:    1.2s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_3a80240a_08a4_11eb_a1c5_98460a89da96row0_col2 {\n",
       "            background-color:  lightgreen;\n",
       "        }    #T_3a80240a_08a4_11eb_a1c5_98460a89da96row0_col3 {\n",
       "            background-color:  lightgreen;\n",
       "        }    #T_3a80240a_08a4_11eb_a1c5_98460a89da96row0_col4 {\n",
       "            background-color:  lightgreen;\n",
       "        }    #T_3a80240a_08a4_11eb_a1c5_98460a89da96row0_col6 {\n",
       "            background-color:  lightgreen;\n",
       "        }    #T_3a80240a_08a4_11eb_a1c5_98460a89da96row0_col7 {\n",
       "            background-color:  lightgreen;\n",
       "        }    #T_3a80240a_08a4_11eb_a1c5_98460a89da96row1_col5 {\n",
       "            background-color:  lightgreen;\n",
       "        }</style><table id=\"T_3a80240a_08a4_11eb_a1c5_98460a89da96\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Estimator</th>        <th class=\"col_heading level0 col1\" >Parameters</th>        <th class=\"col_heading level0 col2\" >mean_precision % (high)</th>        <th class=\"col_heading level0 col3\" >mean_precision % (low)</th>        <th class=\"col_heading level0 col4\" >mean_recall % (high)</th>        <th class=\"col_heading level0 col5\" >mean_recall % (low)</th>        <th class=\"col_heading level0 col6\" >mean_f1 % (high)</th>        <th class=\"col_heading level0 col7\" >mean_f1 % (low)</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_3a80240a_08a4_11eb_a1c5_98460a89da96level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_3a80240a_08a4_11eb_a1c5_98460a89da96row0_col0\" class=\"data row0 col0\" >RandomForest</td>\n",
       "                        <td id=\"T_3a80240a_08a4_11eb_a1c5_98460a89da96row0_col1\" class=\"data row0 col1\" >{}</td>\n",
       "                        <td id=\"T_3a80240a_08a4_11eb_a1c5_98460a89da96row0_col2\" class=\"data row0 col2\" >0.8713</td>\n",
       "                        <td id=\"T_3a80240a_08a4_11eb_a1c5_98460a89da96row0_col3\" class=\"data row0 col3\" >0.8332</td>\n",
       "                        <td id=\"T_3a80240a_08a4_11eb_a1c5_98460a89da96row0_col4\" class=\"data row0 col4\" >0.8217</td>\n",
       "                        <td id=\"T_3a80240a_08a4_11eb_a1c5_98460a89da96row0_col5\" class=\"data row0 col5\" >0.8795</td>\n",
       "                        <td id=\"T_3a80240a_08a4_11eb_a1c5_98460a89da96row0_col6\" class=\"data row0 col6\" >0.8454</td>\n",
       "                        <td id=\"T_3a80240a_08a4_11eb_a1c5_98460a89da96row0_col7\" class=\"data row0 col7\" >0.8555</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_3a80240a_08a4_11eb_a1c5_98460a89da96level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_3a80240a_08a4_11eb_a1c5_98460a89da96row1_col0\" class=\"data row1 col0\" >KNN</td>\n",
       "                        <td id=\"T_3a80240a_08a4_11eb_a1c5_98460a89da96row1_col1\" class=\"data row1 col1\" >{}</td>\n",
       "                        <td id=\"T_3a80240a_08a4_11eb_a1c5_98460a89da96row1_col2\" class=\"data row1 col2\" >0.8671</td>\n",
       "                        <td id=\"T_3a80240a_08a4_11eb_a1c5_98460a89da96row1_col3\" class=\"data row1 col3\" >0.7325</td>\n",
       "                        <td id=\"T_3a80240a_08a4_11eb_a1c5_98460a89da96row1_col4\" class=\"data row1 col4\" >0.6664</td>\n",
       "                        <td id=\"T_3a80240a_08a4_11eb_a1c5_98460a89da96row1_col5\" class=\"data row1 col5\" >0.8963</td>\n",
       "                        <td id=\"T_3a80240a_08a4_11eb_a1c5_98460a89da96row1_col6\" class=\"data row1 col6\" >0.7509</td>\n",
       "                        <td id=\"T_3a80240a_08a4_11eb_a1c5_98460a89da96row1_col7\" class=\"data row1 col7\" >0.8053</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_3a80240a_08a4_11eb_a1c5_98460a89da96level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_3a80240a_08a4_11eb_a1c5_98460a89da96row2_col0\" class=\"data row2 col0\" >SVM</td>\n",
       "                        <td id=\"T_3a80240a_08a4_11eb_a1c5_98460a89da96row2_col1\" class=\"data row2 col1\" >{}</td>\n",
       "                        <td id=\"T_3a80240a_08a4_11eb_a1c5_98460a89da96row2_col2\" class=\"data row2 col2\" >0.6719</td>\n",
       "                        <td id=\"T_3a80240a_08a4_11eb_a1c5_98460a89da96row2_col3\" class=\"data row2 col3\" >0.7231</td>\n",
       "                        <td id=\"T_3a80240a_08a4_11eb_a1c5_98460a89da96row2_col4\" class=\"data row2 col4\" >0.7548</td>\n",
       "                        <td id=\"T_3a80240a_08a4_11eb_a1c5_98460a89da96row2_col5\" class=\"data row2 col5\" >0.6342</td>\n",
       "                        <td id=\"T_3a80240a_08a4_11eb_a1c5_98460a89da96row2_col6\" class=\"data row2 col6\" >0.7108</td>\n",
       "                        <td id=\"T_3a80240a_08a4_11eb_a1c5_98460a89da96row2_col7\" class=\"data row2 col7\" >0.6756</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_3a80240a_08a4_11eb_a1c5_98460a89da96level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_3a80240a_08a4_11eb_a1c5_98460a89da96row3_col0\" class=\"data row3 col0\" >NaiveBayes</td>\n",
       "                        <td id=\"T_3a80240a_08a4_11eb_a1c5_98460a89da96row3_col1\" class=\"data row3 col1\" >{}</td>\n",
       "                        <td id=\"T_3a80240a_08a4_11eb_a1c5_98460a89da96row3_col2\" class=\"data row3 col2\" >0.6869</td>\n",
       "                        <td id=\"T_3a80240a_08a4_11eb_a1c5_98460a89da96row3_col3\" class=\"data row3 col3\" >0.7244</td>\n",
       "                        <td id=\"T_3a80240a_08a4_11eb_a1c5_98460a89da96row3_col4\" class=\"data row3 col4\" >0.7452</td>\n",
       "                        <td id=\"T_3a80240a_08a4_11eb_a1c5_98460a89da96row3_col5\" class=\"data row3 col5\" >0.663</td>\n",
       "                        <td id=\"T_3a80240a_08a4_11eb_a1c5_98460a89da96row3_col6\" class=\"data row3 col6\" >0.7147</td>\n",
       "                        <td id=\"T_3a80240a_08a4_11eb_a1c5_98460a89da96row3_col7\" class=\"data row3 col7\" >0.6921</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_3a80240a_08a4_11eb_a1c5_98460a89da96level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "                        <td id=\"T_3a80240a_08a4_11eb_a1c5_98460a89da96row4_col0\" class=\"data row4 col0\" >AdaBoost</td>\n",
       "                        <td id=\"T_3a80240a_08a4_11eb_a1c5_98460a89da96row4_col1\" class=\"data row4 col1\" >{}</td>\n",
       "                        <td id=\"T_3a80240a_08a4_11eb_a1c5_98460a89da96row4_col2\" class=\"data row4 col2\" >0.7654</td>\n",
       "                        <td id=\"T_3a80240a_08a4_11eb_a1c5_98460a89da96row4_col3\" class=\"data row4 col3\" >0.7373</td>\n",
       "                        <td id=\"T_3a80240a_08a4_11eb_a1c5_98460a89da96row4_col4\" class=\"data row4 col4\" >0.7194</td>\n",
       "                        <td id=\"T_3a80240a_08a4_11eb_a1c5_98460a89da96row4_col5\" class=\"data row4 col5\" >0.7804</td>\n",
       "                        <td id=\"T_3a80240a_08a4_11eb_a1c5_98460a89da96row4_col6\" class=\"data row4 col6\" >0.7413</td>\n",
       "                        <td id=\"T_3a80240a_08a4_11eb_a1c5_98460a89da96row4_col7\" class=\"data row4 col7\" >0.7579</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_3a80240a_08a4_11eb_a1c5_98460a89da96level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "                        <td id=\"T_3a80240a_08a4_11eb_a1c5_98460a89da96row5_col0\" class=\"data row5 col0\" >GradBoost</td>\n",
       "                        <td id=\"T_3a80240a_08a4_11eb_a1c5_98460a89da96row5_col1\" class=\"data row5 col1\" >{}</td>\n",
       "                        <td id=\"T_3a80240a_08a4_11eb_a1c5_98460a89da96row5_col2\" class=\"data row5 col2\" >0.7816</td>\n",
       "                        <td id=\"T_3a80240a_08a4_11eb_a1c5_98460a89da96row5_col3\" class=\"data row5 col3\" >0.7517</td>\n",
       "                        <td id=\"T_3a80240a_08a4_11eb_a1c5_98460a89da96row5_col4\" class=\"data row5 col4\" >0.7346</td>\n",
       "                        <td id=\"T_3a80240a_08a4_11eb_a1c5_98460a89da96row5_col5\" class=\"data row5 col5\" >0.7954</td>\n",
       "                        <td id=\"T_3a80240a_08a4_11eb_a1c5_98460a89da96row5_col6\" class=\"data row5 col6\" >0.7569</td>\n",
       "                        <td id=\"T_3a80240a_08a4_11eb_a1c5_98460a89da96row5_col7\" class=\"data row5 col7\" >0.7726</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7ff990a2ac90>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = {\n",
    "    'RandomForest': RandomForestClassifier(),\n",
    "    'KNN'         : KNeighborsClassifier(weights = \"distance\"),\n",
    "    'SVM'         : SVC(class_weight = \"balanced\"),\n",
    "    'NaiveBayes'  : GaussianNB(),\n",
    "    'AdaBoost'    : AdaBoostClassifier(),\n",
    "    'GradBoost'   : GradientBoostingClassifier()\n",
    "    \n",
    "}\n",
    "\n",
    "params = {\n",
    "    'RandomForest': {\n",
    "    },\n",
    "    'KNN': {\n",
    "    },\n",
    "    'SVM': {   \n",
    "    },\n",
    "    'NaiveBayes': {\n",
    "    },\n",
    "    'AdaBoost': {\n",
    "    },\n",
    "    'GradBoost': {\n",
    "    }\n",
    "}\n",
    "\n",
    "scoring = {\n",
    "    'precision % (high)': make_scorer(precision_score, pos_label = 'good'),\n",
    "    'precision % (low)':  make_scorer(precision_score, pos_label = 'bad'),\n",
    "    'recall % (high)':    make_scorer(recall_score, pos_label = 'good'),\n",
    "    'recall % (low)':     make_scorer(recall_score, pos_label = 'bad'),\n",
    "    'f1 % (high)':        make_scorer(f1_score, pos_label = 'good'),\n",
    "    'f1 % (low)':         make_scorer(f1_score, pos_label = 'bad'),\n",
    "}\n",
    "gs = GridSearchEstimators(models = models, params = params, scoring = scoring)\n",
    "gs.fit(X_train, y_train)\n",
    "report = gs.report()\n",
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Styler' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-10ed51a53a81>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mreport\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean_precision % (high)'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m*\u001b[0m \u001b[0mreport\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean_precision % (high)'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mreport\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean_precision % (low)'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m*\u001b[0m \u001b[0mreport\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean_precision % (low)'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mreport\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean_recall % (high)'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m*\u001b[0m \u001b[0mreport\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean_recall % (high)'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mreport\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean_recall % (low)'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m*\u001b[0m \u001b[0mreport\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean_recall % (low)'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mreport\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean_f1 % (high)'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m*\u001b[0m \u001b[0mreport\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean_f1 % (high)'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Styler' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "report['mean_precision % (high)'] = 100* report['mean_precision % (high)']\n",
    "report['mean_precision % (low)'] = 100* report['mean_precision % (low)']\n",
    "report['mean_recall % (high)'] = 100* report['mean_recall % (high)']\n",
    "report['mean_recall % (low)'] = 100* report['mean_recall % (low)']\n",
    "report['mean_f1 % (high)'] = 100* report['mean_f1 % (high)']\n",
    "report['mean_f1 % (low)'] = 100* report['mean_f1 % (low)']\n",
    "report\n",
    "\n",
    "# dictionary of column colors\n",
    "coldict = {'mean_precision % (low)':'orange', 'mean_recall % (low)':'orange'}\n",
    "\n",
    "def highlight_cols(s, coldict):\n",
    "    if s.name in coldict.keys():\n",
    "        return ['background-color: {}'.format(coldict[s.name])] * len(s)\n",
    "    return [''] * len(s)\n",
    "report.style.apply(highlight_cols, coldict=coldict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These precision, recall and f1 numbers are much better for the bad grade class after correcting for imbalance. \\\n",
    "We are very happy with these results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. More Tuning\n",
    "\n",
    "The RandomForest model seems promising. We tune it some more.\n",
    "\n",
    "After trying more hyperparameters, we don't notice any significant improvements. Using default hyperparameters of Random Forest Classifier is just fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for RandomForest\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:   13.9s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-dc238be6deb3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m }\n\u001b[1;32m     21\u001b[0m \u001b[0mgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchEstimators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/student-success/ML_model/src/utilities/gridSearch.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, cv, n_jobs, verbose)\u001b[0m\n\u001b[1;32m     26\u001b[0m             gs = GridSearchCV(model, params, cv = cv, n_jobs = n_jobs,\n\u001b[1;32m     27\u001b[0m                               verbose = verbose, scoring = self.scoring, refit = False)\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid_searches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    734\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1188\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    713\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 715\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    716\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 934\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    935\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    'RandomForest': RandomForestClassifier(criterion = 'entropy')\n",
    "}\n",
    "\n",
    "params = {\n",
    "    'RandomForest': {\n",
    "        'max_depth': [None, 5, 10, 20],\n",
    "        'min_samples_split': [2, 5, 20],\n",
    "        'n_estimators': [100, 50, 200]\n",
    "    }\n",
    "}\n",
    "\n",
    "scoring = {\n",
    "    'precision (good)': make_scorer(precision_score, pos_label = 'good'),\n",
    "    'precision (bad)':  make_scorer(precision_score, pos_label = 'bad'),\n",
    "    'recall (good)':    make_scorer(recall_score, pos_label = 'good'),\n",
    "    'recall (bad)':     make_scorer(recall_score, pos_label = 'bad'),\n",
    "    'f1 (good)':        make_scorer(f1_score, pos_label = 'good'),\n",
    "    'f1 (bad)':         make_scorer(f1_score, pos_label = 'bad'),\n",
    "}\n",
    "gs = GridSearchEstimators(models = models, params = params, scoring = scoring)\n",
    "gs.fit(X_train, y_train)\n",
    "gs.report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Now Let's see how RandomForest Classifier performs on multiple core courses.\n",
    "\n",
    "The courses examined are either courses that were taken the most throughout 2009 - 2018 or courses that students scored the lowest in. We can easily examine any set of courses GIES wants us to examine too.\n",
    "\n",
    "As we can see the Random Forest model works well on a variety of courses! For all classes, the Random Forest model is able to predict grades with an accuracy of around 85%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BADM 300    3680\n",
       "BADM 449    3658\n",
       "ECON 302    3643\n",
       "BADM 320    3616\n",
       "BADM 310    3601\n",
       "ECON 203    3600\n",
       "FIN 221     3240\n",
       "ACCY 201    3155\n",
       "ACCY 202    3144\n",
       "BUS 388     2805\n",
       "ECON 202    2490\n",
       "FIN 300     1723\n",
       "Name: Course_name, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "courses = ['BADM 449','BADM 320','BADM 300','BADM 310','BUS 388','ECON 202','ECON 203','ECON 302', \n",
    "           'FIN 221', 'FIN 300', 'ACCY 201', 'ACCY 202'\n",
    "           ]\n",
    "course_df = grades_bucketed_df[grades_bucketed_df.Course_name.isin(courses)]\n",
    "course_df.Course_name.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5819 32536\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "bad_grades = 0\n",
    "bad_grades_f = 0\n",
    "cf_matrix= 0 \n",
    "results = defaultdict(list)\n",
    "cf_matrix = 0\n",
    "for course in courses:\n",
    "    course_df = grades_bucketed_df[grades_bucketed_df.Course_name == course]\n",
    "    \n",
    "    # Separate majority and minority classes\n",
    "    grades_good = course_df[course_df.course_grade == \"good\"]\n",
    "    grades_bad  = course_df[course_df.course_grade == \"bad\"]\n",
    "    bad_grades =  bad_grades + grades_bad.shape[0]\n",
    "    # Upsample minority class\n",
    "    course_bad_upsampled = resample(grades_bad, \n",
    "                                     replace = True,     # sample with replacement\n",
    "                                     n_samples = course_df.course_grade.value_counts()['good'],    # to match majority class\n",
    "                                     random_state = 123) # reproducible results\n",
    "    bad_grades_f = bad_grades_f + course_bad_upsampled.shape[0]\n",
    "    # Combine majority class with upsampled minority class\n",
    "    course_upsampled = pd.concat([grades_good, course_bad_upsampled])\n",
    "    # train test split\n",
    "    X = course_upsampled[features]\n",
    "    y = course_upsampled['course_grade']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "    \n",
    "    \n",
    "    # train course RFC model\n",
    "    rfc = RandomForestClassifier(criterion = 'entropy', random_state = 42)\n",
    "    \n",
    "    rfc.fit(X_train, y_train)\n",
    "    pred = rfc.predict(X_test)\n",
    "    class_results = classification_report(y_test, pred, output_dict = True)\n",
    "    results['Course'].append(course)\n",
    "    for label, d in class_results.items():\n",
    "        if label in ['macro avg', 'weighted avg']:\n",
    "            continue\n",
    "        if label == 'accuracy':\n",
    "            results['accuracy'].append(class_results['accuracy'])\n",
    "            continue\n",
    "        for metric, val in d.items():\n",
    "            results[(label, metric)].append(val)\n",
    "    if course=='BADM 310':\n",
    "        cf_matrix = confusion_matrix(y_test,pred)\n",
    "\n",
    "multiIdxCols = [v for v in results.keys() if v not in ['Course', 'accuracy']]\n",
    "cols = pd.MultiIndex.from_tuples(multiIdxCols)\n",
    "res = pd.DataFrame(results, columns = cols, index = results['Course'])\n",
    "print(bad_grades,bad_grades_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# labels = ['True High','False High','False Low','True Low']\n",
    "# labels = np.asarray(labels).reshape(2,2)\n",
    "# sns.heatmap(cf_matrix, annot=labels, fmt='', cmap='Blues')\n",
    "group_names = ['True High','False High','False Low','True Low']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                cf_matrix.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                     cf_matrix.flatten()/np.sum(cf_matrix)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "          zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "sns.heatmap(cf_matrix, annot=labels, fmt='', cmap='Blues')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparse Matrix Classification Model\n",
    "\n",
    "Another approach we attempted was the sparse matrix classification model. In this approach, there are thousands of features. Each feature represents a course and is numeric grade of the student who took the course. If the student has not taken the course, the numeric grade of the student is. 0.0 (hence the sparseness of the matrix).\n",
    "\n",
    "We assume that having taken courses gives the student knowledge that contributes to their success in taking a specific course. Their grade in that course is a proxy for their mastery of the material. The higher the grade, the better their mastery.\n",
    "\n",
    "The code for assembling the sparse matrices is computationally intensive and therefore omitted in this notebook. We directly read in the sparse matrices from pickle files. See `assemble_ml_dataf.ipynb` for code on assembling these sparse matrices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
